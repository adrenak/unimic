{
  "api/Adrenak.UniMic.html": {
    "href": "api/Adrenak.UniMic.html",
    "title": "Namespace Adrenak.UniMic | UniMic documentation",
    "keywords": "Namespace Adrenak.UniMic Classes Mic Provides access to all the recording devices available Mic.Device Provides information and APIs for a single recording device. MicAudioSource A wrapper over StreamedAudioSource to play what a Mic.Device is capturing. StreamedAudioSource"
  },
  "api/Adrenak.UniMic.Mic.Device.html": {
    "href": "api/Adrenak.UniMic.Mic.Device.html",
    "title": "Class Mic.Device | UniMic documentation",
    "keywords": "Class Mic.Device Provides information and APIs for a single recording device. Inheritance System.Object Mic.Device Inherited Members System.Object.ToString() System.Object.Equals(System.Object) System.Object.Equals(System.Object, System.Object) System.Object.ReferenceEquals(System.Object, System.Object) System.Object.GetHashCode() System.Object.GetType() System.Object.MemberwiseClone() Namespace : Adrenak.UniMic Assembly : cs.temp.dll.dll Syntax public class Device Fields DEFAULT_FRAME_DURATION_MS The default duration of the frames in milliseconds Declaration public const int DEFAULT_FRAME_DURATION_MS = 20 Field Value Type Description System.Int32 DEFAULT_SAMPLING_FREQUENCY The default sampling frequency when in uncapped devices that support any frequency. Declaration public const int DEFAULT_SAMPLING_FREQUENCY = 48000 Field Value Type Description System.Int32 Properties ChannelCount The number of channels the audio is captured into. Note that this value is made available ONLY after recording starts and resets to 0 when it stops. Also note that depending on the device, channel count can be changed while the recording is ongoing use OnFrameCollected to react to such changes. Declaration public int ChannelCount { get; } Property Value Type Description System.Int32 FrameDurationMS The duration of the audio frame (in milliseconds) that would be reported by the device. Note that, for example, setting this value to 50 does not mean you would predictably receive 20 frames representing 50ms of audio at fixed and regular intervals. Often times, sent multiple may be sent multiple times in a single game frame or with varying intervals between the frames. For playback, consider creating a buffer. See MicAudioSource for references. Declaration public int FrameDurationMS { get; } Property Value Type Description System.Int32 FrameLength The length of a single PCM frame array that will be sent via OnFrameCollected Declaration public int FrameLength { get; } Property Value Type Description System.Int32 IsRecording Whether this device is currently recording audio Declaration public bool IsRecording { get; } Property Value Type Description System.Boolean MaxFrequency The maximum sampling frequency this device supports Declaration public int MaxFrequency { get; } Property Value Type Description System.Int32 MinFrequency The minimum sampling frequency this device supports Declaration public int MinFrequency { get; } Property Value Type Description System.Int32 Name The name of the recording device Declaration public string Name { get; } Property Value Type Description System.String SamplingFrequency The sampling frequency this device is recording at Declaration public int SamplingFrequency { get; } Property Value Type Description System.Int32 SupportsAnyFrequency If this device is capable of supporting any sampling frequency Declaration public bool SupportsAnyFrequency { get; } Property Value Type Description System.Boolean VolumeMultiplier Multiplies the incoming PCM samples by the given value to increase/decrease the volume. Default: 1 Declaration public float VolumeMultiplier { get; set; } Property Value Type Description System.Single Methods StartRecording(Int32) Start recording audio using this device. If the device is capped (has a min and max frequency) it starts at the maximum frequency supported. If the device isn't capped (supports any frequency) it starts at 48KHz. The frameDuration is DEFAULT_FRAME_DURATION_MS unless specified. Declaration public void StartRecording(int frameDurationMS = 20) Parameters Type Name Description System.Int32 frameDurationMS The audio length of one frame (in MS) StartRecording(Int32, Int32) Start recording audio using this device at the provided sampling frequency and frame duration Declaration public void StartRecording(int samplingFrequency, int frameDurationMS = 20) Parameters Type Name Description System.Int32 samplingFrequency System.Int32 frameDurationMS StopRecording() Stop recording audio Declaration public void StopRecording() Events OnFrameCollected Invoked everytime an audio sample is collected. Params: (sampling frequency, channel count, PCM samples) You use the channel count provided to be able to react to it changing Declaration public event Action<int, int, float[]> OnFrameCollected Event Type Type Description System.Action < System.Int32 , System.Int32 , System.Single []> OnStartRecording Invoked when the instance starts Recording. Declaration public event Action OnStartRecording Event Type Type Description System.Action OnStopRecording Invoked when the instance stop Recording. Declaration public event Action OnStopRecording Event Type Type Description System.Action"
  },
  "api/Adrenak.UniMic.Mic.html": {
    "href": "api/Adrenak.UniMic.Mic.html",
    "title": "Class Mic | UniMic documentation",
    "keywords": "Class Mic Provides access to all the recording devices available Inheritance System.Object Mic Namespace : Adrenak.UniMic Assembly : cs.temp.dll.dll Syntax public class Mic : MonoBehaviour Constructors Mic() Declaration [Obsolete(\"Mic is a MonoBehaviour singleton that is created on its own upon usage.\", true)] public Mic() Properties AvailableDevices Gets the available recording devices Declaration public static List<Mic.Device> AvailableDevices { get; } Property Value Type Description System.Collections.Generic.List < Mic.Device > Methods Init() Initialize the Mic class for use. Declaration public static void Init()"
  },
  "api/Adrenak.UniMic.MicAudioSource.html": {
    "href": "api/Adrenak.UniMic.MicAudioSource.html",
    "title": "Class MicAudioSource | UniMic documentation",
    "keywords": "Class MicAudioSource A wrapper over StreamedAudioSource to play what a Mic.Device is capturing. Inheritance System.Object MicAudioSource Namespace : Adrenak.UniMic Assembly : cs.temp.dll.dll Syntax public class MicAudioSource : MonoBehaviour Properties Device Declaration public Mic.Device Device { get; set; } Property Value Type Description Mic.Device StreamedAudioSource Declaration public StreamedAudioSource StreamedAudioSource { get; } Property Value Type Description StreamedAudioSource"
  },
  "api/Adrenak.UniMic.Samples.html": {
    "href": "api/Adrenak.UniMic.Samples.html",
    "title": "Namespace Adrenak.UniMic.Samples | UniMic documentation",
    "keywords": "Namespace Adrenak.UniMic.Samples Classes MicDeviceCell MicudioSourceSwitchSample MultipleMicAudioSourceSample SimpleMicAudioSourceSample SpatialBlendSample"
  },
  "api/Adrenak.UniMic.Samples.MicDeviceCell.html": {
    "href": "api/Adrenak.UniMic.Samples.MicDeviceCell.html",
    "title": "Class MicDeviceCell | UniMic documentation",
    "keywords": "Class MicDeviceCell Inheritance System.Object MicDeviceCell Namespace : Adrenak.UniMic.Samples Assembly : cs.temp.dll.dll Syntax public class MicDeviceCell : MonoBehaviour Fields deviceNameText Declaration public Text deviceNameText Field Value Type Description Text isRecordingToggle Declaration public Toggle isRecordingToggle Field Value Type Description Toggle rmsIndicator Declaration public Image rmsIndicator Field Value Type Description Image Methods SetDeviceName(String) Declaration public void SetDeviceName(string name) Parameters Type Name Description System.String name SetIsRecording(Boolean) Declaration public void SetIsRecording(bool state) Parameters Type Name Description System.Boolean state SetRMS(Single) Declaration public void SetRMS(float value) Parameters Type Name Description System.Single value"
  },
  "api/Adrenak.UniMic.Samples.MicudioSourceSwitchSample.html": {
    "href": "api/Adrenak.UniMic.Samples.MicudioSourceSwitchSample.html",
    "title": "Class MicudioSourceSwitchSample | UniMic documentation",
    "keywords": "Class MicudioSourceSwitchSample Inheritance System.Object MicudioSourceSwitchSample Namespace : Adrenak.UniMic.Samples Assembly : cs.temp.dll.dll Syntax public class MicudioSourceSwitchSample : MonoBehaviour"
  },
  "api/Adrenak.UniMic.Samples.MultipleMicAudioSourceSample.html": {
    "href": "api/Adrenak.UniMic.Samples.MultipleMicAudioSourceSample.html",
    "title": "Class MultipleMicAudioSourceSample | UniMic documentation",
    "keywords": "Class MultipleMicAudioSourceSample Inheritance System.Object MultipleMicAudioSourceSample Namespace : Adrenak.UniMic.Samples Assembly : cs.temp.dll.dll Syntax public class MultipleMicAudioSourceSample : MonoBehaviour"
  },
  "api/Adrenak.UniMic.Samples.SimpleMicAudioSourceSample.html": {
    "href": "api/Adrenak.UniMic.Samples.SimpleMicAudioSourceSample.html",
    "title": "Class SimpleMicAudioSourceSample | UniMic documentation",
    "keywords": "Class SimpleMicAudioSourceSample Inheritance System.Object SimpleMicAudioSourceSample Namespace : Adrenak.UniMic.Samples Assembly : cs.temp.dll.dll Syntax public class SimpleMicAudioSourceSample : MonoBehaviour"
  },
  "api/Adrenak.UniMic.Samples.SpatialBlendSample.html": {
    "href": "api/Adrenak.UniMic.Samples.SpatialBlendSample.html",
    "title": "Class SpatialBlendSample | UniMic documentation",
    "keywords": "Class SpatialBlendSample Inheritance System.Object SpatialBlendSample Namespace : Adrenak.UniMic.Samples Assembly : cs.temp.dll.dll Syntax public class SpatialBlendSample : MonoBehaviour"
  },
  "api/Adrenak.UniMic.StreamedAudioSource.html": {
    "href": "api/Adrenak.UniMic.StreamedAudioSource.html",
    "title": "Class StreamedAudioSource | UniMic documentation",
    "keywords": "Class StreamedAudioSource Inheritance System.Object StreamedAudioSource Namespace : Adrenak.UniMic Assembly : cs.temp.dll.dll Syntax public class StreamedAudioSource : MonoBehaviour Constructors StreamedAudioSource() Declaration [Obsolete(\"new not allowed. Use StreamedAudioSource.New\", true)] public StreamedAudioSource() Properties BufferDurationMS The length of the internal buffer in milliseconds Declaration public int BufferDurationMS { get; } Property Value Type Description System.Int32 BufferFactor The multiplier for the buffer length. Declaration public int BufferFactor { get; set; } Property Value Type Description System.Int32 Buffering Declaration [Obsolete(\"This property has been deprecated. Use IsBuffering instead.\")] public bool Buffering { get; } Property Value Type Description System.Boolean ChannelCount Current clip's channel count Declaration public int ChannelCount { get; } Property Value Type Description System.Int32 FrameCountForPlay Declaration [Obsolete(\"FrameCountForPlay is no longer supported. Use targetLatency instead to configure buffer size.\")] public int FrameCountForPlay { get; set; } Property Value Type Description System.Int32 FrameLifetime Maximum time to keep audio in buffer before discarding it Declaration public float FrameLifetime { get; set; } Property Value Type Description System.Single IsBuffering Whether audio is currently being fed and buffered for playback eventually. Declaration public bool IsBuffering { get; } Property Value Type Description System.Boolean IsPlaying Whether playback is currently running Declaration public bool IsPlaying { get; } Property Value Type Description System.Boolean PitchMaxCorrection Caps pitch adjustment so audio doesn't sound unnatural Declaration public float PitchMaxCorrection { get; set; } Property Value Type Description System.Single PitchProportionalGame Controls how aggressively pitch is adjusted to reach target latency Declaration public float PitchProportionalGame { get; set; } Property Value Type Description System.Single SamplingFrequency Current clip's sample rate Declaration public int SamplingFrequency { get; } Property Value Type Description System.Int32 TargetLatency Target delay between receiving and playing audio Declaration public float TargetLatency { get; set; } Property Value Type Description System.Single UnityAudioSource Accessor for AudioSource with lazy initialization and setup Declaration public AudioSource UnityAudioSource { get; } Property Value Type Description AudioSource Methods Feed(Int32, Int32, Single[]) Feeds audio into the buffer. Reinitializes format if it changes. Starts playback when target latency is reached. Declaration public void Feed(int frequency, int channels, float[] samples) Parameters Type Name Description System.Int32 frequency System.Int32 channels System.Single [] samples Feed(Int32, Int32, Single[], Boolean) Declaration [Obsolete(\"Feed no longer needs autoPlayWhenReady. Auto play is always on.\")] public void Feed(int frequency, int channels, float[] samples, bool autoPlayWhenReady = true) Parameters Type Name Description System.Int32 frequency System.Int32 channels System.Single [] samples System.Boolean autoPlayWhenReady New(String) Declaration public static StreamedAudioSource New(string name = null) Parameters Type Name Description System.String name Returns Type Description StreamedAudioSource Play() Declaration [Obsolete(\"Play() is no longer supported. Calling this method will do nothing. When enough audio has been buffered the audio will always play automatically.\")] public void Play() Stop() Declaration [Obsolete(\"Stop() is no longer supported. Calling this method will do nothing. If you want to stop playback, stop calling the Feed method and playback will end automatically when the buffer is cleared. For immediately stopping playback consider setting UnityAudioSource.volume to 0\")] public void Stop()"
  },
  "index.html": {
    "href": "index.html",
    "title": "UniMic 🎤 | UniMic documentation",
    "keywords": "UniMic 🎤 A wrapper for Unity's Microphone class. Provides easy APIs for mic input and management. Also includes StreamedAudioSource , a (not Microphone related) class that can be used for playing streaming audio by feeding it incoming audio samples. Documentation 📝 Refer to the Scripting Reference Installing 📦 ⚠️ OpenUPM doesn't have up to date releases. Install using NPM registry instead 👇 Ensure you have the NPM registry in the packages.json file of your Unity project with com.adrenak.unimic as one of the scopes \"scopedRegistries\": [ { \"name\": \"npmjs\", \"url\": \"https://registry.npmjs.org\", \"scopes\": [ \"com.npmjs\", \"com.adrenak.unimic\" ] } } Add \"com.adrenak.unimic\" : \"x.y.z\" to dependencies list in packages.json file where x.y.z is the version name 💬 You can see the versions on the NPM page here . Also note that v3.x.x is recommended. v3 has several breaking changes against v1 and v2. Refer to the scripting reference if you're upgrading. Samples 🚀 Getting started with some samples is the best way to see the features of UniMic, and there are many! Ensure that atleast one recording device is connected to your PC/Mac for the samples to work. Simple MicAudioSource Sample A gameobject called My Mic is placed. It has the MicAudioSource component. Another gmeobject called Sample has SimpleMicAudioSourceSample On start it checks if there are any mic devices available If yes, it takes the first recording device available and starts the recording using .StartRecording() Then assigns the device to MicAudioSource , which then starts playing the audio Play the scene. You should be able to hear your voice in the editor Multiple MicAudioSource Sample Run the scene, you should see every mic device connected On start, all the devices will start recording in parallel and playing back Toggling the checkbox on or off will start or stop the recording for a device Prefab MicDeviceCell is used to represent one device. The MicDeviceCell.cs script handles its UI. Check out the MultipleMicAudioSourceSample script to see how the UI has been created MicAudioSource Switch Sample Run the scene, recording should start on one device and a dropdown will show all the available recording devices Use the dropdown to change to a difference device at runtime Check out the MicAudioSourceSwitchSample script to see how the Device of a MicAudioSource can be changed at runtime. Spatial Blend Sample (for spatial audio) Run the scene, the audio source is a moving ball. When you speak, your audio is played from the balls position. Use headphones to hear the sound moving. Using the slider, you can change the spatial blend from 0 to 1 Note 📄 Some Xiaomi phones may prevent side loaded APKs from functioning. There is no AEC (Acoustic Echo Cancelletion). If you're trying the samples be sure to use headphones to avoid creating a feedback loop. Contact 👥 @github @website @discord: adrenak#1934"
  }
}